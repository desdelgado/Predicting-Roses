{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Engineering for Season 15\n",
    "\n",
    "This is just a quick script to load all the data from season 15.  Most of the code is copied from [part 2](https://github.com/desdelgado/Predicting_Roses/blob/master/Rose_Data_Engineering_P2.ipynb) and thus I won't narrate as much.   The exception being that my girlfriend and I were keeping track of certain statistics such as first impression rose and one on on dates as the season went on.  We kept a excel file and I used that to load in some of the features of each contestant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['', 'Name', '', 'Age', '', 'Hometown', '', 'Occupation', '', 'Outcome',\n",
      "       '', 'Place', '', 'Ref', ''],\n",
      "      dtype='object', name=0)\n"
     ]
    }
   ],
   "source": [
    "seasons_wiki = ['https://en.wikipedia.org/wiki/The_Bachelorette_(season_15)']\n",
    "wiki_df = pd.DataFrame()\n",
    "missed_season_tracker = []\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "for season in seasons_wiki:\n",
    "\n",
    "    try:\n",
    "        URL= season\n",
    "        response = requests.get(URL)\n",
    "        soup = BeautifulSoup(response.text, 'lxml')\n",
    "        \n",
    "        #Need to add additional try statment because\n",
    "        try:\n",
    "            My_table = soup.find(\"table\",{\"class\" :\"wikitable sortable\"})\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        try:\n",
    "            My_table = soup.find(\"table\",{\"class\" :\"wikitable\"})\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        contest = []\n",
    "        \n",
    "        for record in My_table.findAll('tr'):\n",
    "                contest.append(record.text)\n",
    "        \n",
    "        #Convert list into dataframe\n",
    "        \n",
    "        contest_df = pd.DataFrame(contest)\n",
    "        \n",
    "        #Split the dataframe by the \\n\n",
    "        contest_df = contest_df.iloc[:,0].str.split('\\n', expand = True)\n",
    "        \n",
    "        new_header = contest_df.iloc[0] #grab the first row for the header\n",
    "        contest_df.columns = new_header\n",
    "        \n",
    "        contest_df = contest_df.iloc[1:]\n",
    "        print(contest_df.columns)\n",
    "        \n",
    "        \n",
    "        occup = contest_df[['Name', 'Hometown','Age', 'Outcome']]\n",
    "        \n",
    "        #need to get which season we are working with in order to construct the name to merge the tables with\n",
    "        #instead of inputting a list use a regrex equations to pull the season number out of the wiki url\n",
    "        season_number = int(re.findall('\\d+', URL )[0])\n",
    "        \n",
    "        occup['SEASON'] = season_number\n",
    "        \n",
    "        \n",
    "        #Getting the strings \n",
    "        occup['Name'] = occup['Name'].str.replace('\\d+', '')\n",
    "        occup.Name = occup.Name.str.strip('[]')\n",
    "        occup.Name = occup.Name.str.strip('.')\n",
    "        \n",
    "        occup.Age = occup.Age.str.extract('(\\d+)')\n",
    "        \n",
    "        #Have to check the varity of names make sure to talk about this \n",
    "        \n",
    "        #If they have the nickname grab the middle one\n",
    "        occup.loc[occup['Name'].str.split().str.len() == 3, 'First_name'] = occup['Name'].str.split().str[1]\n",
    "        #If they have just two names grab the first\n",
    "        occup.loc[occup['Name'].str.split().str.len() == 2, 'First_name'] = occup['Name'].str.split().str[0]\n",
    "        #If they have just one name like in the ealier seasons\n",
    "        occup.loc[occup['Name'].str.split().str.len() == 1, 'First_name'] = occup['Name'].str.split().str[0]\n",
    "        #strip the parathesis\n",
    "        occup.First_name = occup.First_name.str.strip(' \"\" ')\n",
    "        #grab the last names\n",
    "        \n",
    "        #could use this concept to speed up HT match loop\n",
    "        occup.loc[occup['Name'].str.split().str.len() == 3, 'Last_name'] = occup.Name.str.split().str[-1]\n",
    "        occup.loc[occup['Name'].str.split().str.len() == 2, 'Last_name'] = occup.Name.str.split().str[-1]\n",
    "        occup.loc[occup['Name'].str.split().str.len() == 1, 'Last_name'] = 'X'\n",
    "        \n",
    "        occup['Last_name'] = occup['Last_name'].astype(str).str[0]\n",
    "                \n",
    "        \n",
    "        occup[\"Name\"] = occup[\"First_name\"].map(str) + '_' + occup[\"Last_name\"]\n",
    "                \n",
    "        #Adds a 0 if the season is less than 9 so we can properly match stuff\n",
    "        #print(occup.SEASON)\n",
    "        if occup.SEASON.iloc[0] > 9:\n",
    "            occup[\"Name\"] = occup[\"SEASON\"].map(str) + '_' + occup[\"Name\"]           \n",
    "        else:\n",
    "            occup[\"Name\"] = '0'+ occup[\"SEASON\"].map(str) + '_' + occup[\"Name\"]\n",
    "        \n",
    "        #strip any hidden spaces\n",
    "        occup.Name = occup.Name.str.strip()\n",
    "        \n",
    "        occup.Name = occup.Name.str.upper()\n",
    "        #Rename it to match the elim_data table\n",
    "        occup.rename(columns={'Name':'CONTESTANT'}, inplace=True)\n",
    "        wiki_df = pd.concat([wiki_df, occup], sort = True)\n",
    "    except:\n",
    "        print('Missed season: ' + season)\n",
    "        \n",
    "        missed_season_tracker.append(season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_15 = wiki_df[['CONTESTANT','Hometown', 'Age', 'SEASON']]\n",
    "\n",
    "#%% Make a table we will eventually use in our trained model\n",
    "Validation_15 = pd.DataFrame(wiki_df['CONTESTANT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_england = ['Maine', 'Vermont', 'New Hampshire', 'Massachusetts', 'Rhode Island', 'Connecticut']\n",
    "#Could put Maryland somewhere else\n",
    "south = ['Alabama','Florida', 'Georgia', 'Kentucky', 'Louisiana', 'Mississippi',\n",
    "         'North Carolina', 'South Carolina', 'West Virgina', \n",
    "         'Virgina', 'Maryland', 'Tennessee']\n",
    "midatlatic = ['Pennsylvania', 'New Jersey', 'Delaware', 'New York']\n",
    "upper_midwest = ['Ohio','Indiana', 'Illinois', 'Michigan','Wisconsin', 'Iowa', 'Minnesota','Nebraska',\n",
    "                 'North Dakota', 'South Dakota', 'Nebraska']\n",
    "lower_midwest = ['Kansas', 'Missouri']\n",
    "northern_mountain = ['Montana', 'Idaho', 'Wyoming']\n",
    "northwest = ['Washington', 'Oregon']\n",
    "southwest = ['Arizona', 'New Mexico', 'Texas', 'Oklahoma', 'Arizona']\n",
    "mountain = ['Colorado','Utah']\n",
    "west = ['California', 'Nevada', 'Alaska', 'Hawaii']\n",
    "\n",
    "regions = new_england + south + midatlatic + upper_midwest +lower_midwest + northern_mountain + northwest +southwest+ mountain +west\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_15['Home State'] = season_15['Hometown'].str.split(\",\").str[1].str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findregion(ind):\n",
    "    homestate = ind.get(key = 'Home State')\n",
    "    if homestate in new_england:\n",
    "        return 'New England'\n",
    "    elif homestate in south:\n",
    "        return 'South'\n",
    "    elif homestate in midatlatic:\n",
    "        return 'Midatlatic'    \n",
    "    elif homestate in upper_midwest:\n",
    "        return 'Upper midwest'\n",
    "    elif homestate in lower_midwest:\n",
    "        return 'Lower Midwest'\n",
    "    elif homestate in northern_mountain:\n",
    "        return 'Northern Mountain'    \n",
    "    elif homestate in northwest:\n",
    "        return 'Northwest'    \n",
    "    elif homestate in southwest:\n",
    "        return 'Southwest'    \n",
    "    elif homestate in mountain:\n",
    "        return 'Mountain'    \n",
    "    elif homestate in west:\n",
    "        return 'West'   \n",
    "    #In case the contestant comes from outside the US\n",
    "    else:\n",
    "        return homestate\n",
    "    \n",
    "season_15['Home State'] = season_15['Home State'].str.strip()\n",
    "season_15['Culture Region'] = season_15.apply(findregion, axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "season_15['Culture Region'].isnull().any().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bachelorettesHT = pd.read_excel('Bachelorette_Data/Hometown_Bacherlorette.xlsx')\n",
    "\n",
    "bachelorettesHT['Home State'] = bachelorettesHT['Hometown'].str.split(\",\").str[1].str.strip()\n",
    "bachelorettesHT['Culture Region'] = bachelorettesHT.apply(findregion, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_15['Match Region'] = 0\n",
    "season_15['Match City'] = 0\n",
    "\n",
    "#%%\n",
    "          \n",
    "bachelorettesHT.index = bachelorettesHT['Bachelorette']\n",
    "season_15.index = season_15['CONTESTANT']\n",
    "\n",
    "for row in bachelorettesHT.index.tolist():\n",
    "    for contest in season_15.index.tolist():\n",
    "        if (bachelorettesHT.loc[row,'Season'] == season_15.loc[contest, 'SEASON']) and (bachelorettesHT.loc[row,'Culture Region'] == season_15.loc[contest, 'Culture Region']):\n",
    "            season_15.loc[contest, 'Match Region'] = 1\n",
    "            if bachelorettesHT.loc[row,'Hometown'] == season_15.loc[contest, 'Hometown']:\n",
    "                season_15.loc[contest, 'Match City'] = 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Validation_15 = pd.merge(Validation_15, season_15[['CONTESTANT','Match Region', 'Match City']], on = 'CONTESTANT')      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_leanings = pd.read_csv('Bachelorette_Data/state_leanings.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "canada_pol = pd.read_csv('Bachelorette_Data/Canada_Wiki.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setCanPolitical(ind):\n",
    "    lean = ind.get(key = 'Canada Leanings')\n",
    "    if lean == 'Centre-right':\n",
    "        return 2\n",
    "    elif lean == 'Centre-left to left-wing':\n",
    "        return -7\n",
    "    elif lean == 'Centre to centre-right':\n",
    "        return 5    \n",
    "    elif lean == 'Centre to centre-left':\n",
    "        return -5\n",
    "    #non partisan\n",
    "    else:\n",
    "        return 0\n",
    " \n",
    "canada_pol['Canada Leanings'] = canada_pol.apply(setCanPolitical, axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FindPolLean(on_going_table, PVI_table, canada_table):\n",
    "    '''\n",
    "        In takes data table you are working with and the polictical table pulled from\n",
    "        the internet and gives you a number that indicates their PVI - is Liberal + is conservative\n",
    "        0 is either even or not in the USA\n",
    "        On going table should have a 'Home State' column and PVI_Table should have a \"State\" table\n",
    "        \n",
    "        Canada table needs to have table labeled \"Province/Territory\"\n",
    "    '''\n",
    "    on_going_table = on_going_table.merge(PVI_table, how = 'left', left_on = 'Home State', right_on = 'State')\n",
    "    on_going_table = on_going_table.replace('EVEN', 'N+0')\n",
    "    on_going_table['PVI'] = on_going_table['PVI'].astype(str)\n",
    "    #season_15['PVI'] = season_15['PVI'].str.strip('+')\n",
    "    #Need to split the values based on political parties\n",
    "    on_going_table['PVI'] = on_going_table['PVI'].str.split(\"+\") \n",
    "    \n",
    "    def setPolitical(ind):\n",
    "        pair = ind.get(key = 'PVI')\n",
    "        if pair[0] == 'R':\n",
    "            return int(pair[1])\n",
    "        elif pair[0] == 'D':\n",
    "            point = int(pair[1])\n",
    "            return point*-1\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    on_going_table['Poltical Spectrum'] = on_going_table.apply(setPolitical, axis = 1)   \n",
    "    on_going_table = on_going_table.drop(['State', 'PVI'], axis = 1)\n",
    "    \n",
    "    on_going_table = on_going_table.merge(canada_table, how = 'left', left_on = 'Home State', right_on = 'Province/Territory')\n",
    "    \n",
    "    #add Canada's leanings    \n",
    "    def addCanLean(ind):\n",
    "        canada_regions = ['Alberta','British Columbia','Manitoba','New Brunswick',\n",
    "                          'Newfoundland and Labrador','Nova Scotia','Ontario','Prince Edward Island',\n",
    "                          'Quebec','Saskatchewan','Northwest Territories','Nunavut','Yukon']\n",
    "        if ind.get(key = 'Home State') in canada_regions:\n",
    "            return ind.get(key = 'Canada Leanings')\n",
    "        else:\n",
    "            return ind.get(key = 'Poltical Spectrum')\n",
    "    \n",
    "    on_going_table['PVI'] = on_going_table.apply(addCanLean, axis = 1)\n",
    "    on_going_table = on_going_table.drop(['Poltical Spectrum', 'Canada Leanings', 'Province/Territory'], axis = 1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return on_going_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_15 = FindPolLean(season_15,state_leanings, canada_pol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bachelorettesHT = FindPolLean(bachelorettesHT, state_leanings, canada_pol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bachelorette_pol_lean = pd.DataFrame({\n",
    "    \"Season\": bachelorettesHT.Season,\n",
    "    \"B_PVI\": bachelorettesHT.PVI,\n",
    "    \"B_Age\": bachelorettesHT.Age})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_15 = season_15.merge(bachelorette_pol_lean, left_on = 'SEASON', right_on = 'Season')\n",
    "season_15 = season_15.drop('Season', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_15['Political Difference'] = season_15.PVI - season_15.B_PVI\n",
    "season_15['Age Difference'] = season_15.Age.astype(int) - season_15.B_Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Validation_15 = pd.merge(Validation_15, season_15[['CONTESTANT','Political Difference', 'Age Difference']], on = 'CONTESTANT', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "round_data = pd.read_excel('Bachelorette_Data/season_15_Elim.xlsx')\n",
    "\n",
    "round_data = round_data.drop(['Round D1', 'GF_pick'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Validation_15 = pd.merge(Validation_15, round_data, on = 'CONTESTANT', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     CONTESTANT  Match Region  Match City  Political Difference  \\\n",
      "0      15_JED_W             1           0                   0.0   \n",
      "1    15_TYLER_C             1           0                 -12.0   \n",
      "2    15_PETER_W             0           0                 -26.0   \n",
      "3     15_LUKE_P             1           0                  -9.0   \n",
      "4  15_GARRETT_P             1           0                   0.0   \n",
      "\n",
      "   Age Difference  Round_Eliminated  First_Impression_Rose  \\\n",
      "0               1                11                      0   \n",
      "1               2                10                      0   \n",
      "2               3                 9                      0   \n",
      "3               0                 9                      1   \n",
      "4               3                 7                      0   \n",
      "\n",
      "   Percentage Left after D1  \n",
      "0                        60  \n",
      "1                        60  \n",
      "2                        40  \n",
      "3                        50  \n",
      "4                         0  \n"
     ]
    }
   ],
   "source": [
    "Validation_15.to_csv('Bachelorette_Data/Validation_15.csv')\n",
    "\n",
    "print(Validation_15.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "'Python Interactive'",
   "language": "python",
   "name": "7181ece0-cf42-4c63-ab7c-45dd15154ce0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
